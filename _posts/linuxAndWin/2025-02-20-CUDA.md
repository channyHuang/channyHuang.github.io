---
layout: default
title: 在Windows上使用onnxruntime/openvino进行模型推理部署
categories:
- Linux
tags:
- Server
- Linux
---
//Description: 记录在Windows上使用onnxruntime/openvino进行模型推理部署过程中的笔记，写于2025年3月

//Create Date: 2025-02-20 14:20:28

//Author: channy

[toc]

# 在Windows上使用onnxruntime/openvino进行模型推理部署
代码见[OnnxInference](https://github.com/channyHuang/OnnxInference)
## 结论
### 综合
1. OpenCV的dnn对输入输出为图像数据的模型比较友好，对输入或输出非图像数据的模型有可能会不支持。
### onnxruntime
2. 微软的[onnxruntime](https://github.com/microsoft/onnxruntime)不同的版本对应系统中VC++ runtime不同的版本
3. onnxruntime中的dll需要放到exe可执行文件同一目录下，否则运行会直接崩溃。。。
4. onnxruntime的模型加载接口用到了wchar_t*类型，注意编码，utf8的需要转换
5. 对Intel的CPU+集显GPU，onnxruntime貌似只能调用CPU，运行速度有点慢（2s/帧，对应openvino调用GPU 0.5s/帧），onnxruntime调用GPU暂未尝试成功
### openvino
0. windows下使用动态库需要把dll都放到exe可执行文件同一目录下，否则运行会报找不到“GPU“之类的错误，但实际上只是没找到依赖dll
1. 可以成功调用Intel的集显GPU，比onnxruntime单纯调用CPU快（0.5s/帧 vs 2s/帧）
2. openvino对windows、linux、debian都有现成的动静态库可以直接从官网下载直接使用，无需安装，其它系统如Kylin貌似需要从源码编译
## 背景及模型准备
Linux上训练了一个视频编解码的.pt模型，需要在其它平台（Windows）使用解码推理。

先使用'torch.onnx.export'导出成.onnx模型，注意查看其中的opset_version默认值，后面可能要用到

```sh
mo --input_model model.onnx --output_dir ir_output
```

## 坑1 运行崩溃（0xc00007b）问题
需要把onnxruntime的dll放置到exe可执行文件同一目录下。它不像OpenCV没有dll会直接报“找不到OpenCVxxx.dll”，而是直接崩溃。。。

## 坑2 报错版本不支持后崩溃
```sh
The given version [20] is not supported, only version 1 to 10 is supported in this build
```
一开始用的是onnxruntime 1.20.1版本在Linux上正常在Windows上vs2022运行直接崩溃。后面在别的电脑上vs2019运行同样崩溃，报的该错误。推测是版本相关问题。

查看官网每一版的Release说明中有写哪哪版开始不再支持VC++ Runtime xxx版本以下。

| vs | c++ runtime | 
|:---:|:---:|
| vs2022 | 14.30 |
| vs2019 | 14.20 |
| vs2017 | 14.10 |
| vs2015 | 14.00 |
| vs2013 | 12.00 |
| vs2012 | 11.00 |
| vs2010 | 10.00 |

换成onnxruntime 1.10.0后正常，确认是版本问题

## 坑3 模型路径名称utf8编码和宽字节问题
```c++
try {
  // ...
  // 加载模型
  m_pSession = new Ort::Session(m_env, pModelPath, m_sessionOptions);
  // ...
} catch (std::exception&e) {
  printf("init Get Exception: [%s]\n", e.what());
}
```
其中模型加载中'Ort::Session'参数二的类型是`const ORTCHAR_T*`，在Linux下是`#define ORTCHAR_T char`没问题，在Windows下是`#define ORTCHAR_T wchar_t`直接强行转换
```c++
m_pSession = new Ort::Session(m_env, (const ORTCHAR_T*), m_sessionOptions);
```
在Windows下大概率是乱码，通过exception的打印可以看到报找不到模型的错误。
```c++
std::wstring_convert<std::codecvt_utf8<wchar_t>> converter;
std::wstring wsModelPath = converter.from_bytes(pModelPath); 
m_pSession = new Ort::Session(m_env, wsModelPath.c_str(), m_sessionOptions);
```
可以用stl库函数直接转换。

## 坑4 模型转换opset_version版本匹配问题
其中onnxruntime 1.10最高只支持opset=15的.onnx模型，使用python的onnxruntime 1.16.0转换默认是opset=17太高了不支持

# CUDA多版本切换
## 版本查看
```sh
$ ls /usr/local
bin   cuda-12    cuda-12.5  games    lib  sbin   src
cuda  cuda-12.1  etc        include  man  share
```

```sh
$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Wed_Apr_17_19:19:55_PDT_2024
Cuda compilation tools, release 12.5, V12.5.40
Build cuda_12.5.r12.5/compiler.34177558_0
```

```sh
$ nvidia-smi
Thu Feb 20 14:10:24 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3090        Off |   00000000:55:00.0  On |                  N/A |
| 53%   68C    P0            201W /  350W |   16523MiB /  24576MiB |     11%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A      1957      G   /usr/lib/xorg/Xorg                             35MiB |
|    0   N/A  N/A      2799      G   /usr/lib/xorg/Xorg                            163MiB |
|    0   N/A  N/A      2937      G   /usr/bin/gnome-shell                           54MiB |
|    0   N/A  N/A      3498      G   ...sion,SpareRendererForSitePerProcess         81MiB |
|    0   N/A  N/A     63928      C   python3                                     16138MiB |
+-----------------------------------------------------------------------------------------+

```

## 版本安装
[CUDA-Toolkit](https://developer.nvidia.com/cuda-toolkit-archive)
多个版本安装过程中去掉`Driver`显卡驱动安装

[12.1](https://developer.nvidia.com/cuda-12-1-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_network)

## 版本切换
添加到update-alternatives
```sh
sudo update-alternatives --install /usr/local/cuda cuda /usr/local/cuda-12.1 121
sudo update-alternatives --install /usr/local/cuda cuda /usr/local/cuda-12.5 125
```
切换
```sh
$ sudo update-alternatives --config cuda
update-alternatives --config cuda
There are 2 choices for the alternative cuda (providing /usr/local/cuda).

  Selection    Path                  Priority   Status
------------------------------------------------------------
* 0            /usr/local/cuda-12.5   125       auto mode
  1            /usr/local/cuda-12     10        manual mode
  2            /usr/local/cuda-12.5   125       manual mode

Press <enter> to keep the current choice[*], or type selection number: 
```
切换后验证`nvcc -V`

# Orin刷机
[Reference](https://blog.csdn.net/weixin_53776054/article/details/128552701)
## Ubuntu台式机环境准备

[ubuntu-ports](https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu-ports/)

[Nvidia SDK Manager](https://developer.nvidia.com/sdk-manager)

```sh
sudo apt install ./sdkmanager_2.1.0-11698_amd64.deb
sudo apt get update
```

## 刷机
### 进入Recovery模式
```
Put the device into reset/recovery mode.

    Power on the carrier board and hold down the Recovery button.

    Press the Reset button.
```

台式机通过命令`lsusb`确认是否进入Recovery模式
```
$ lsusb

Bus <bbb> Device <ddd>: ID 0955: <nnnn> Nvidia Corp.

```
[Recovery Mode](https://docs.nvidia.com/jetson/archives/r36.4/DeveloperGuide/IN/QuickStart.html#to-determine-whether-the-developer-kit-is-in-force-recovery-mode)

### SDK Manager
```sh
$ sdkmanager
```
根据提示下载安装

## 开发环境
PyTorch需要安装特定版本
[PyTorch](https://forums.developer.nvidia.com/t/pytorch-for-jetson/72048)
[torch][https://developer.download.nvidia.cn/compute/redist/jp/v61/pytorch/]
[forum](https://forums.developer.nvidia.com/t/jetpack6-1-install-torchvision/310007/9)